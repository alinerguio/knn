{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataIris(porcentage_testing):\n",
    "    data_iris = pd.read_table('../data/iris.csv', sep=',') # three classifications ('Iris-setosa, Iris-versicolor and Iris-virginica')\n",
    "    data_iris = data_iris.drop(['Id'], axis=1)\n",
    "    data_iris = data_iris.rename(columns={'SepalLengthCm': 0, 'SepalWidthCm': 1, 'PetalLengthCm': 2, 'PetalWidthCm': 3, 'Species': 4})\n",
    "    num_testing = (data_iris.shape[0] / 3) * porcentage_testing\n",
    "    testing_iris = data_iris.head(1)\n",
    "    data_iris = data_iris.drop([0])\n",
    "    \n",
    "    total_testing = num_testing * 3\n",
    "    \n",
    "    for index, row in data_iris.iterrows():\n",
    "        if testing_iris.shape[0] < total_testing:\n",
    "            if len(data_iris) > index:\n",
    "                if row[4] == 'Iris-setosa' and (testing_iris.loc[testing_iris[4] == 'Iris-setosa']).shape[0] < num_testing \\\n",
    "                    or row[4] == 'Iris-versicolor' and (testing_iris.loc[testing_iris[4] == 'Iris-versicolor']).shape[0] < num_testing \\\n",
    "                    or row[4] == 'Iris-virginica' and (testing_iris.loc[testing_iris[4] == 'Iris-virginica']).shape[0] < num_testing:\n",
    "                    testing_iris = testing_iris.append(data_iris.iloc[index]) \n",
    "                    data_iris = data_iris.drop([index])\n",
    "\n",
    "    training_iris = data_iris \n",
    "    training_iris = training_iris.reset_index()\n",
    "    training_iris = training_iris.drop(['index'], axis=1)\n",
    "    testing_iris = testing_iris.reset_index()\n",
    "    testing_iris = testing_iris.drop(['index'], axis=1)\n",
    "    \n",
    "    return training_iris, testing_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataSpamBase(porcentage_testing):\n",
    "    data_spambase = pd.read_table('../data/spambase.data', sep=',', header=None) # two classifications (1 or 0)\n",
    "    num_testing = (data_spambase.shape[0] / 2) * porcentage_testing\n",
    "    testing_spambase = data_spambase.head(1)\n",
    "    data_spambase = data_spambase.drop([0])\n",
    "    \n",
    "    total_testing = num_testing * 2\n",
    "    \n",
    "    for index, row in data_spambase.iterrows():\n",
    "        if testing_spambase.shape[0] < total_testing:\n",
    "            if len(data_spambase) > index:\n",
    "                if row[57] == 0 and (testing_spambase.loc[testing_spambase[57] == 0]).shape[0] < num_testing \\\n",
    "                or row[57] == 1 and (testing_spambase.loc[testing_spambase[57] == 1]).shape[0] < num_testing:\n",
    "                    testing_spambase = testing_spambase.append(data_spambase.iloc[index]) \n",
    "                    data_spambase = data_spambase.drop([index])\n",
    "    \n",
    "    training_spambase = data_spambase\n",
    "    training_spambase = training_spambase.reset_index()\n",
    "    training_spambase = training_spambase.drop(['index'], axis=1)\n",
    "    testing_spambase = testing_spambase.reset_index()\n",
    "    testing_spambase = testing_spambase.drop(['index'], axis=1)\n",
    "    \n",
    "    return training_spambase, testing_spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidianDistance(testing, training):\n",
    "    all_distances = []\n",
    "    num_columns = testing.shape[1] - 1\n",
    "    num_rows_testing = testing.shape[0]\n",
    "    \n",
    "    for i in range(num_rows_testing):\n",
    "        all_distances.append([])\n",
    "    \n",
    "    for index_train, row_train in training.iterrows():\n",
    "        for test in range(num_rows_testing):\n",
    "            distance = 0 \n",
    "            for i in range(num_columns): # ultima coluna é a classificação\n",
    "                distance += (float(testing.loc[test][i]) - float(row_train[i])) ** 2\n",
    "                \n",
    "            all_distances[test].append([math.sqrt(distance), row_train[num_columns]])\n",
    "\n",
    "    for i in range(num_rows_testing):\n",
    "        identification = [[i, testing.loc[i][4]]]\n",
    "        all_distances[i].sort()\n",
    "        all_distances[i] = identification + all_distances[i]\n",
    "        \n",
    "        \n",
    "    return all_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificationKNN(distance_list, k):\n",
    "    classification = []\n",
    "    for i in range(1, k+1):\n",
    "        classification.append(distance_list[i][1])\n",
    "    \n",
    "    result = Counter(classification).most_common()[0][0]\n",
    "    \n",
    "    return [distance_list[0][1], result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(distances, testing, k):\n",
    "    num_testing = testing.shape[0]\n",
    "    num_columns = testing.shape[1]\n",
    "    column_values = testing[num_columns - 1].drop_duplicates().tolist() \n",
    "    \n",
    "    confusion_matrix = pd.DataFrame(0, index=column_values, columns=column_values)\n",
    "    input_data = []\n",
    "    predicted_data = []\n",
    "    \n",
    "    for i in range(num_testing):\n",
    "        result = classificationKNN(distances[i], k)\n",
    "        input_data.append(result[0])\n",
    "        predicted_data.append(result[1])\n",
    "        confusion_matrix.loc[result[0], result[1]] = confusion_matrix.loc[result[0], result[1]] + 1\n",
    "            \n",
    "    \n",
    "    return confusion_matrix, input_data, predicted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyseMachineLearning(input_data, predicted_data):\n",
    "    print(\"\\nAcurácia: \", accuracy_score(input_data, predicted_data))\n",
    "    print(\"\\nRecall: \", recall_score(input_data, predicted_data, average=None))\n",
    "    print(\"\\nPrecisão: \", precision_score(input_data, predicted_data, average=None))\n",
    "    print(\"\\nF-score: \", f1_score(input_data, predicted_data, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeKNN(training, testing):\n",
    "    k_list = [1, 3, 5, 7]\n",
    "    distances = euclidianDistance(testing, training)\n",
    "    \n",
    "    for k in k_list:\n",
    "        print('\\nK = ', k)\n",
    "        confusion_matrix, input_data, predicted_data = confusionMatrix(distances, testing, k)\n",
    "        print('\\nMatriz de Confusão: ')\n",
    "        print(confusion_matrix)\n",
    "        analyseMachineLearning(input_data, predicted_data)\n",
    "        print('\\n---------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IRIS DATA\n",
      "\n",
      "\n",
      "Testing with  50.0 % of the data.\n",
      "\n",
      "K =  1\n",
      "\n",
      "Matriz de Confusão: \n",
      "                 Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "Iris-setosa               25                0               0\n",
      "Iris-versicolor            0               11               2\n",
      "Iris-virginica             0                0              25\n",
      "\n",
      "Acurácia:  0.9682539682539683\n",
      "\n",
      "Recall:  [1.         0.84615385 1.        ]\n",
      "\n",
      "Precisão:  [1.         1.         0.92592593]\n",
      "\n",
      "F-score:  [1.         0.91666667 0.96153846]\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n",
      "K =  3\n",
      "\n",
      "Matriz de Confusão: \n",
      "                 Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "Iris-setosa               25                0               0\n",
      "Iris-versicolor            0               10               3\n",
      "Iris-virginica             0                0              25\n",
      "\n",
      "Acurácia:  0.9523809523809523\n",
      "\n",
      "Recall:  [1.         0.76923077 1.        ]\n",
      "\n",
      "Precisão:  [1.         1.         0.89285714]\n",
      "\n",
      "F-score:  [1.         0.86956522 0.94339623]\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n",
      "K =  5\n",
      "\n",
      "Matriz de Confusão: \n",
      "                 Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "Iris-setosa               25                0               0\n",
      "Iris-versicolor            0                9               4\n",
      "Iris-virginica             0                0              25\n",
      "\n",
      "Acurácia:  0.9365079365079365\n",
      "\n",
      "Recall:  [1.         0.69230769 1.        ]\n",
      "\n",
      "Precisão:  [1.         1.         0.86206897]\n",
      "\n",
      "F-score:  [1.         0.81818182 0.92592593]\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n",
      "K =  7\n",
      "\n",
      "Matriz de Confusão: \n",
      "                 Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "Iris-setosa               25                0               0\n",
      "Iris-versicolor            0                9               4\n",
      "Iris-virginica             0                0              25\n",
      "\n",
      "Acurácia:  0.9365079365079365\n",
      "\n",
      "Recall:  [1.         0.69230769 1.        ]\n",
      "\n",
      "Precisão:  [1.         1.         0.86206897]\n",
      "\n",
      "F-score:  [1.         0.81818182 0.92592593]\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "porcentage_testing = 0.5\n",
    "training, testing = prepareDataIris(porcentage_testing)\n",
    "print('\\nIRIS DATA\\n')\n",
    "print('\\nTesting with ', porcentage_testing * 100, '% of the data.')\n",
    "executeKNN(training, testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentage_testing = 0.5 \n",
    "training, testing = prepareDataSpamBase(porcentage_testing)\n",
    "print('\\nSPAM BASE DATA\\n')\n",
    "print('\\nTesting with ', porcentage_testing * 100, '% of the data.')\n",
    "executeKNN(training, testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
